{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sacrasm",
      "provenance": [],
      "collapsed_sections": [
        "Zp70yGLjsBa4",
        "7APO5LGyJve6"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Icrz11/CS114.K21/blob/master/Sacrasm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbx8QKcjX5_5",
        "colab_type": "text"
      },
      "source": [
        "Thành viên thực hiện\n",
        "\n",
        "#Nguyễn Hữu Khang - 18520892\n",
        "#Hồ Đăng Tuệ - 18521611\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w55FltNxsq8o",
        "colab_type": "text"
      },
      "source": [
        "#Giới thiệu về Bài toán nhận biết Sarcasm\n",
        "  * Trong thực tế có rất nhiều title báo giật tít trên các trang báo lá cải, cũng như mạng xã hội\n",
        "\n",
        "  * Vì vậy mà việc detect các title này để xác minh tin nào là tin chính thống, tin nào là tin châm biếm đang là vấn đề lớn (phát triển rộng hơn nữa là bài toán về kiểm tra fake news)\n",
        "\n",
        "  * Dataset được sử dụng trong bài toán này có sẵn ở kaggle, và được thu thập từ 2 nguồn đó là trang web https://www.huffpost.com/ - chuyên tin chính thống, cùng với  https://www.theonion.com/ - Chuyên tin lá cải\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ7_YOOU81It",
        "colab_type": "text"
      },
      "source": [
        "#Cách thu thâp Dataset:\n",
        "\n",
        "> Sử dụng tool có tên Data Miner (công cụ có sẵn ở google chrome)\n",
        "Link của tool: https://data-miner.io/\n",
        "\n",
        "Sao khi mở tool lên, ta tạo 1 receipt mới\n",
        "1. Start\n",
        "2. Rows - Các cột trong file mà ta sẽ xuất ra ở đây ta cần thu thập headline, cho nên headline sẽ là 1 cột trong Rows\n",
        "3. Cols - Nếu ta cần thêm thông tin nào nữa thì chỉ cần add thêm column vào và quay lại tab Rows để bổ sung nội dung hiển thị trong column đó\n",
        "4. Nav - Đại loại là ta sẽ thu thập tiếp tục dữ liệu ở 1 trang kế tiếp và gắn dữ liệu đó vào đuôi của dữ liệu đã crawl trước đó\n",
        "5. Actions - ta sẽ thực hiện 1 số hành động như kéo tới cuối trang, click vào 1 button nào đó\n",
        "6. JS - để add Script vào\n",
        "7. Save - để save là receipt của ta\n",
        "\n",
        "Em sử dụng tab Rows + Nav + Save để hoàn thành receipt crawl dữ liệu của mình\n",
        "\n",
        "> Rows em sẽ chọn nội dung là các headline mình cần crawl\n",
        "\n",
        "> Nav em sẽ set nút button để chuyển \n",
        "\n",
        "> Cuối cùng là save lại Receipt và chạy tự động để crawl dữ liệu về"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq1yd6R4r6LZ",
        "colab_type": "text"
      },
      "source": [
        "# Lấy Data từ Kaggle về"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfy4lp7KlPAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d4268413-fc06-4280-b5d7-46793df05baa"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Icrz11/CS114.K21/master/Sarcasm_Headlines_Dataset.json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-26 12:25:20--  https://raw.githubusercontent.com/Icrz11/CS114.K21/master/Sarcasm_Headlines_Dataset.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5616830 (5.4M) [text/plain]\n",
            "Saving to: ‘Sarcasm_Headlines_Dataset.json’\n",
            "\n",
            "\r          Sarcasm_H   0%[                    ]       0  --.-KB/s               \r         Sarcasm_He  34%[=====>              ]   1.87M  9.37MB/s               \rSarcasm_Headlines_D 100%[===================>]   5.36M  14.6MB/s    in 0.4s    \n",
            "\n",
            "2020-06-26 12:25:20 (14.6 MB/s) - ‘Sarcasm_Headlines_Dataset.json’ saved [5616830/5616830]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLoY2X7y2suP",
        "colab_type": "text"
      },
      "source": [
        "Download file Sarcasm Headline từ github (được em lưu sẵn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJHnADAoKlyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b83c7454-cd3a-4329-e268-7f610709d949"
      },
      "source": [
        "#read data\n",
        "import pandas as pd\n",
        "df = pd.read_json(\"/content/Sarcasm_Headlines_Dataset.json\", lines = True)\n",
        "df.head()\n",
        "df = df.drop(['article_link'], axis = 1)\n",
        "print (df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                headline  is_sarcastic\n",
            "0      former versace store clerk sues over secret 'b...             0\n",
            "1      the 'roseanne' revival catches up to our thorn...             0\n",
            "2      mom starting to fear son's web series closest ...             1\n",
            "3      boehner just wants wife to listen, not come up...             1\n",
            "4      j.k. rowling wishes snape happy birthday in th...             0\n",
            "...                                                  ...           ...\n",
            "26704               american politics in moral free-fall             0\n",
            "26705                            america's best 20 hikes             0\n",
            "26706                              reparations and obama             0\n",
            "26707  israeli ban targeting boycott supporters raise...             0\n",
            "26708                  gourmet gifts for the foodie 2014             0\n",
            "\n",
            "[26709 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lXfOeidsXQ5",
        "colab_type": "text"
      },
      "source": [
        "> Dùng pandas đọc file .json \n",
        "\n",
        "> Kế đến ta sẽ drop cột article link đi (vì cột này không cần thiết lắm trong bài toán của ta)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mykCALK3MwAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "06c4e9ca-367c-4e39-c497-ea396920683f"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26709 entries, 0 to 26708\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   headline      26709 non-null  object\n",
            " 1   is_sarcastic  26709 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 417.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YajgBPT4trCm",
        "colab_type": "text"
      },
      "source": [
        "1 số info từ Data ta vừa thu thâp được, trong đó data này có 26709 mẫu bao gồm 2 thông tin là headlibe + nhãn có phải là tin châm biếm hay không"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuENvsb7PfCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import neighbors\n",
        "import string \n",
        "from string import digits\n",
        "from string import punctuation\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "for i in df['headline']:\n",
        "  i = str(i)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMafPNAxt94z",
        "colab_type": "text"
      },
      "source": [
        "Import tất các thư viện cần dùng trong bài toán này\n",
        "\n",
        "1. Numpy - Xử lí các ma trận\n",
        "2. Sklearn - Các hàm liên quan đến thuật toán máy học cũng như đánh giá model\n",
        "3. String - thư viện xử lí các kí tự "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgXNzoxNugBa",
        "colab_type": "text"
      },
      "source": [
        "# Tiền xử lí dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VMsuUMcyh9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fa212d65-28c8-4c17-bf51-7be1fb22b881"
      },
      "source": [
        "hl_clean = []\n",
        "for i in df['headline']:\n",
        "  clean = i.translate(str.maketrans('', '', punctuation))\n",
        "  clean = clean.translate(str.maketrans('', '', digits))\n",
        "  hl_clean.append(clean)\n",
        "\n",
        "print('Before: ')\n",
        "print(df['headline'][37])\n",
        "print ('After: ')\n",
        "print (hl_clean[37])\n",
        "for i in hl_clean:\n",
        "  i = i.lower()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before: \n",
            "'moana' sails straight to the top of the box office with massive $81.1 million opening\n",
            "After: \n",
            "moana sails straight to the top of the box office with massive  million opening\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8zJqoiLuq0c",
        "colab_type": "text"
      },
      "source": [
        "Loại bỏ các thành phần không đóng vai trò quan trọng trong câu của chúng ta\n",
        "\n",
        "Các thành phần bị loại bỏ:\n",
        "> Các chữ số \n",
        "\n",
        "> Các dấu câu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wougL2lw4bgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f6aa3294-c25d-4f8b-b8fa-35afdf2222d4"
      },
      "source": [
        "hl_tokens = []\n",
        "for i in hl_clean:\n",
        "  i = i.split()\n",
        "  hl_tokens.append(i)\n",
        "\n",
        "print ('before: ')\n",
        "print (hl_clean[100])\n",
        "print ('after: ')\n",
        "print (hl_tokens[100])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before: \n",
            "demi lovato drops emotional nightingale music vid\n",
            "after: \n",
            "['demi', 'lovato', 'drops', 'emotional', 'nightingale', 'music', 'vid']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwhSps-bu3Tj",
        "colab_type": "text"
      },
      "source": [
        "Tách các từ trong câu ra thành các token riêng lẽ ở trên là ví dụ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQBTfv7QmBuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b11c9f96-d994-4391-aa29-658a2ccdb299"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "Lemmantizer = WordNetLemmatizer()\n",
        "hl_lemma = []\n",
        "count = 0\n",
        "print (hl_tokens[10])\n",
        "for i in (hl_tokens):\n",
        "  hl_lemma.append([])\n",
        "  for j in i:\n",
        "    hl_lemma[count].append(Lemmantizer.lemmatize(j))\n",
        "  count+=1\n",
        "print (hl_lemma[10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "['airline', 'passengers', 'tackle', 'man', 'who', 'rushes', 'cockpit', 'in', 'bomb', 'threat']\n",
            "['airline', 'passenger', 'tackle', 'man', 'who', 'rush', 'cockpit', 'in', 'bomb', 'threat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs8tVilzvW7o",
        "colab_type": "text"
      },
      "source": [
        "Chuyển toàn bộ từ về form cơ bản của nó\n",
        "\n",
        "Ví dụ: goes -> go\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT6F_mLBiMrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "27afb835-c35e-4d53-cef9-796b9a331b83"
      },
      "source": [
        "import nltk\n",
        "nltk.download ('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words = list(stop_words)\n",
        "hl_re = []\n",
        "count = 0\n",
        "for i in hl_lemma:\n",
        "  hl_re.append([])\n",
        "  for j in i:\n",
        "    if (j not in stop_words):\n",
        "      hl_re[count].append(j)\n",
        "  count+=1\n",
        "\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkMpWMNhRKIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "741413ef-9edb-4c0a-dbc5-1ab8a0348258"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "Lemmantizer = WordNetLemmatizer()\n",
        "def Preprocessing_Data (Headline):\n",
        "  Headline = Headline.lower()\n",
        "  #Dùng để loại bỏ các dấu câu, chữ số\n",
        "  clean = Headline.translate(str.maketrans('', '', punctuation))\n",
        "  clean = clean.translate(str.maketrans('', '', digits))\n",
        "  #Tách các từ ra thành các token\n",
        "  clean = clean.split()\n",
        "  #Chuyển chúng về dạng \"root\" của chúng\n",
        "  result = []\n",
        "  for i in clean:\n",
        "    result.append(Lemmantizer.lemmatize(i))\n",
        "  return result"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9IQ6l0hJ2qM",
        "colab_type": "text"
      },
      "source": [
        "# Đưa dữ liệu vào model để Trainning (sử dụng bag of words để features extraction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UYKtFGtMdiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = hl_re\n",
        "wordfreq = {}\n",
        "for i in tmp:\n",
        "  for token in i:\n",
        "    if token not in wordfreq.keys():\n",
        "      wordfreq[token] = 1\n",
        "    else:\n",
        "      wordfreq[token] += 1\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yraw0xYUFWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sort_wordfreq = sorted(wordfreq.items(), key=lambda x: x[1], reverse=True)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQlenp4qUbWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector_len = 2000\n",
        "tmp2 = []\n",
        "for i in range (vector_len):\n",
        "  tmp2.append(sort_wordfreq[i][0])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_70cEYYPnoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_vectors = []\n",
        "for sentence in hl_re:\n",
        "  sent_vec = np.zeros(shape = (vector_len,))\n",
        "  for i,token in enumerate(tmp2):\n",
        "    if token in sentence:\n",
        "      sent_vec[i] = 1\n",
        "  sentence_vectors.append(sent_vec)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZD1xBUmdMih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Bag_Of_Word(Headline):\n",
        "  sent_vec = np.zeros(shape = (vector_len,))\n",
        "  for i in range (len(Headline)):\n",
        "    if (Headline[i] in tmp2):\n",
        "      sent_vec[i] = 1\n",
        "    return sent_vec"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34UiW00hZIP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c7e657bc-c193-416e-9bc9-90753331f787"
      },
      "source": [
        "Y = df.iloc[:,1]\n",
        "X = sentence_vectors\n",
        "X = np.array (X)\n",
        "Y = np.array(Y)\n",
        "print (len(X))\n",
        "print (len(Y))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26709\n",
            "26709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG81R-NVZZEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split (X,Y, test_size = 0.2, random_state = 30)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53yuwypJmD_2",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQRd0GhwmGf5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88afa239-aec4-4aea-d05d-a0117380b775"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model1 = GaussianNB()\n",
        "model1.fit (X_train, y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBkH5Zshmf8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re1 = model1.predict (X_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4OqSMAWnfUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eac62843-5445-4211-c62b-396760370b68"
      },
      "source": [
        "confusion_matrix(y_test, re1).ravel()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1817, 1190,  426, 1909])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8gczaARn-lr",
        "colab_type": "text"
      },
      "source": [
        "Từ confusion matrix ta thấy được số nhãn được:\n",
        "\n",
        "1817 -> Số nhãn được dự đoán đúng thuộc loại negative (TN) | 1190 -> Số nhãn được dự đoán sai loại positive (FP)\n",
        "\n",
        "426 -> Số nhãn được dự đoán sai loại Negative | 1909 -> Số nhãn được dự đoán đúng thuộc loại positive\n",
        "\n",
        "Với negative = 0 và positive = 1 (0 là non sacrasm và 1 là sacrasm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpPAr0dAnljr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "11629c71-8c34-43de-a05b-a6581dc0d564"
      },
      "source": [
        "f1_model1 = f1_score(y_test, re1)\n",
        "print (\"F1_score: \", f1_model1)\n",
        "print (\"Accurancy: \",accuracy_score(y_test, re1))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_score:  0.7026131762973868\n",
            "Accurancy:  0.6974915761886934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6PE3f8Lusq1",
        "colab_type": "text"
      },
      "source": [
        "Ta thấy chỉ số F1-score ở model này khá cao (0.70) với F1 score được tính bởi \n",
        "\n",
        "$ (2*Precision*Recall) \n",
        "/ (Precision + Recall) $\n",
        "\n",
        "Cho nên nếu cả precision và recall đều cao thì F1 - score mới cao được\n",
        "\n",
        "\n",
        "      > $Precision = 1909 / (1909 + 426) = 0.817$\n",
        "\n",
        "      > $Recall = 1909 / (1909 + 1190) = 0.61$\n",
        "\n",
        ">Precision biểu thị cho việc tiên đoán số nhãn true positive tronng số những điểm được phân loại là positive \n",
        "\n",
        ">Recall biểu thị việc tiên đoán số nhãn True trong những điểm thật sự là positive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLmDpSUGmG2j",
        "colab_type": "text"
      },
      "source": [
        "### K-NN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmiJmm0HmI83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a93d57ee-9f36-4b09-a187-315e5dccad8d"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model2 = KNeighborsClassifier()\n",
        "model2.fit (X_train, y_train)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_xnEs-FmjYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re2 = model2.predict (X_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "istvAQqLpyNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ea50adc-3d0a-4e15-9a36-c4fb748b0ffd"
      },
      "source": [
        "confusion_matrix(y_test, re2).ravel()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2032,  975,  998, 1337])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yafCaD1HNKiC",
        "colab_type": "text"
      },
      "source": [
        "2032 -> Số nhãn được dự đoán đúng thuộc loại negative (TN) | 975 -> Số nhãn được dự đoán sai loại positive (FP)\n",
        "\n",
        "998 -> Số nhãn được dự đoán sai loại Negative | 1337 -> Số nhãn được dự đoán đúng thuộc loại positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO_Zs6sAp0_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "12440223-532d-4ef8-87b0-014173756f5e"
      },
      "source": [
        "f1_model2 = f1_score(y_test, re2)\n",
        "print (\"F1_score: \", f1_model2)\n",
        "print (\"Accurancy: \",accuracy_score(y_test, re2))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_score:  0.5754250053798149\n",
            "Accurancy:  0.6306626731561213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCqe540RMbhP",
        "colab_type": "text"
      },
      "source": [
        " F1 - score ở model KNN là 0.57 và Accurancy là 0.63, cả 2 đều khá thấp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8SzMmZFmJkv",
        "colab_type": "text"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trHOOyygmRis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "080e2d35-e37d-4b75-fad7-02424f1fab4d"
      },
      "source": [
        "from sklearn import svm\n",
        "model3 = svm.SVC()\n",
        "model3.fit (X_train, y_train)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJLqvwRgmkxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re3 = model3.predict (X_test)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS1_3SEt9Z66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cb4818b-9fb6-4220-b5bd-d15afef4b8fe"
      },
      "source": [
        "confusion_matrix(y_test, re3).ravel()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2593,  414,  791, 1544])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB6Y0ZR7Ng_Y",
        "colab_type": "text"
      },
      "source": [
        "2593 -> Số nhãn được dự đoán đúng thuộc loại negative (TN) | 414 -> Số nhãn được dự đoán sai loại positive (FP)\n",
        "\n",
        "791 -> Số nhãn được dự đoán sai loại Negative | 1554 -> Số nhãn được dự đoán đúng thuộc loại positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ouJfbGF9dT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4827c9a7-e37a-4242-b500-f947cd053b9c"
      },
      "source": [
        "f1_model3 = f1_score(y_test, re3)\n",
        "print (\"F1_score: \", f1_model3)\n",
        "print (\"Accurancy: \",accuracy_score(y_test, re3))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_score:  0.7193105054740274\n",
            "Accurancy:  0.7744290527892175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHdGEZAbObeq",
        "colab_type": "text"
      },
      "source": [
        " F1 - score ở model SVM là 0.71 và Accurancy là 0.77 Đây là model ổn nhất"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeHdtYA9KHMX",
        "colab_type": "text"
      },
      "source": [
        "### Lưu và Load model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puX0_1D8KJwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ev0xkW4KMfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9623eb0-23b4-4831-9521-3e1cdfe51113"
      },
      "source": [
        "joblib.dump(model1, 'model_sac_naivebayes.sav')\n",
        "joblib.dump(model2, 'model_sac_KNN.sav')\n",
        "joblib.dump(model3, 'model_sac_SVM.sav')"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_sac_SVM.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtNpln-_LORI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = joblib.load('')\n",
        "model2 = joblib.load('')\n",
        "model3 = joblib.load('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxNX6Z84Ul4m",
        "colab_type": "text"
      },
      "source": [
        ":v em lưu lại model nhưng kh post lại trên github được do dung lượng file khá nặng, thầy chạy lại từ đầu giúp em <3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7APO5LGyJve6",
        "colab_type": "text"
      },
      "source": [
        "# Đưa dữ liệu gồm 2k headline được crawl về để test model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXWrPGLmKGOz",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOcYHWEampQv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "018ec9d8-bdf7-4b39-d65b-a07c3136e7d0"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Icrz11/CS114.K21/master/test_data.csv"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-26 12:30:11--  https://raw.githubusercontent.com/Icrz11/CS114.K21/master/test_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 165600 (162K) [text/plain]\n",
            "Saving to: ‘test_data.csv’\n",
            "\n",
            "\rtest_data.csv         0%[                    ]       0  --.-KB/s               \rtest_data.csv       100%[===================>] 161.72K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-06-26 12:30:12 (3.73 MB/s) - ‘test_data.csv’ saved [165600/165600]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EGBOQdosG2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c2b3a8ec-fa7b-44f8-caf3-4aadc81c4ca2"
      },
      "source": [
        "test = pd.read_csv ('/content/test_data.csv')\n",
        "test.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BirthdayForBreonna Marks What Would've Been Br...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TheShowMustBePaused Was Eclipsed By #BlackOutT...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Again, Again, Again!' Exclaims Clapping, Grinn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>And Then There Were 23,' Says Wayne Messam Cro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>And Then Those 12 People Send It To 12 People ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  BirthdayForBreonna Marks What Would've Been Br...             0\n",
              "1  TheShowMustBePaused Was Eclipsed By #BlackOutT...             0\n",
              "2  Again, Again, Again!' Exclaims Clapping, Grinn...             1\n",
              "3  And Then There Were 23,' Says Wayne Messam Cro...             1\n",
              "4  And Then Those 12 People Send It To 12 People ...             1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEOW8n7102kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = test['is_sarcastic']\n",
        "Y = np.array(Y)\n",
        "X = test['headline']"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfxmzd3t8JH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "87b1bbb3-1a2d-4e23-cc74-be0021a05933"
      },
      "source": [
        "X.head()\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    BirthdayForBreonna Marks What Would've Been Br...\n",
              "1    TheShowMustBePaused Was Eclipsed By #BlackOutT...\n",
              "2    Again, Again, Again!' Exclaims Clapping, Grinn...\n",
              "3    And Then There Were 23,' Says Wayne Messam Cro...\n",
              "4    And Then Those 12 People Send It To 12 People ...\n",
              "Name: headline, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLys_WvUWrUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "for i in X:\n",
        "  X_train.append(Preprocessing_Data(i))\n",
        "kHeadline = []\n",
        "for i in X_train:\n",
        "  kHeadline.append(Bag_Of_Word(i))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAVEkgOxaf3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re_test1 = model1.predict (kHeadline)\n",
        "re_test2 = model2.predict (kHeadline)\n",
        "re_test3 = model3.predict (kHeadline)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S6uUi28BRgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a2af25ce-dbc2-46ea-b4e7-068b1a0b2f8e"
      },
      "source": [
        "print (\"confusion matrix cua Naive Bayes:\\n\",confusion_matrix(Y, re_test1).ravel())\n",
        "print (\"confusion matrix cua KNN:\\n\",confusion_matrix(Y, re_test2).ravel())\n",
        "print (\"confusion matrix cua SVM:\\n\",confusion_matrix(Y, re_test3).ravel())\n"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix cua Naive Bayes:\n",
            " [   0 1156    0 1003]\n",
            "confusion matrix cua KNN:\n",
            " [580 576 524 479]\n",
            "confusion matrix cua SVM:\n",
            " [1156    0 1003    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJjoJsP1Ei7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "909ccff8-b513-4abe-ceff-8387e562e4b6"
      },
      "source": [
        "print ('Naive Bayes:\\n', classification_report(Y, re_test1))\n",
        "print ('\\n')\n",
        "print ('accurancy cua Naive Bayes: ',accuracy_score(Y, re_test1))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1156\n",
            "           1       0.46      1.00      0.63      1003\n",
            "\n",
            "    accuracy                           0.46      2159\n",
            "   macro avg       0.23      0.50      0.32      2159\n",
            "weighted avg       0.22      0.46      0.29      2159\n",
            "\n",
            "\n",
            "\n",
            "accurancy cua Naive Bayes:  0.4645669291338583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jI15sR9OpAQ",
        "colab_type": "text"
      },
      "source": [
        "Ta thấy model khi test trên tập dữ liệu 2k headline mới thì chỉ số recall cao ngất ngưỡng (1.0) có nghĩa là trong 2k headline mới thì khả năng model phát hiện 1 tin có phải sacrasm là 100%, tuy nhiên precision của model khá thấp (0.46) có nghĩa là model có 46% đúng khi khẳng định 1 tin là sacrasm (Model tiên đoán khá tệ). \n",
        "\n",
        "=> Model dự đoán tất cả headline đầu vào là sacrasm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-blpBXvIFyZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "58d19712-ed45-4830-a15f-4cd967f4b77b"
      },
      "source": [
        "print ('KNN:\\n', classification_report(Y, re_test2))\n",
        "print ('\\n')\n",
        "print ('accurancy cua KNN: ',accuracy_score(Y, re_test2))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.50      0.51      1156\n",
            "           1       0.45      0.48      0.47      1003\n",
            "\n",
            "    accuracy                           0.49      2159\n",
            "   macro avg       0.49      0.49      0.49      2159\n",
            "weighted avg       0.49      0.49      0.49      2159\n",
            "\n",
            "\n",
            "\n",
            "accurancy cua KNN:  0.4905048633626679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6Xfd870RgB6",
        "colab_type": "text"
      },
      "source": [
        "Tuy chỉ số recall cũng như precision của model KNN không cao, nhưng có thể chấp nhận được hơn là model Naive Bayes ở trên\n",
        "\n",
        "=> Model dự đoán tất cả headline đầu vào là sacrasm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9-gLRphFz5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "f063dadb-df54-4914-a28b-a45dd8c10dd6"
      },
      "source": [
        "print ('SVM:\\n',classification_report(Y, re_test3))\n",
        "print ('\\n')\n",
        "print ('accurancy cua SVM : ',accuracy_score(Y, re_test3))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      1.00      0.70      1156\n",
            "           1       0.00      0.00      0.00      1003\n",
            "\n",
            "    accuracy                           0.54      2159\n",
            "   macro avg       0.27      0.50      0.35      2159\n",
            "weighted avg       0.29      0.54      0.37      2159\n",
            "\n",
            "\n",
            "\n",
            "accurancy cua SVM :  0.5354330708661418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HAZ1-RURx0G",
        "colab_type": "text"
      },
      "source": [
        "Tương tự như model Naive Bayes, model cũng dự đoán sai hoàn toàn\n",
        "\n",
        "Lần này model dự đoán tất cả headline đầu vào đều không phải là sacrasm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SAqjwp3cOO0",
        "colab_type": "text"
      },
      "source": [
        "# Chương trình đưa vào 1 Headline và dự đoán"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1UG6rkacTTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e0d40e1e-cce4-4a73-bad2-b0e11eb20797"
      },
      "source": [
        "#Bag of word\n",
        "Inp = input ('Moi nhap headline: ')\n",
        "Inp = Preprocessing_Data(Inp)\n",
        "Inp = Bag_Of_Word(Inp)\n",
        "Inp = np.array(Inp)\n",
        "Inp = Inp.reshape(1, -1)\n",
        "Kqua1 = model1.predict(Inp)\n",
        "Kqua2 = model2.predict(Inp)\n",
        "Kqua3 = model3.predict(Inp)\n",
        "def check(Kqua):\n",
        "  if (Kqua == 1):\n",
        "    re = 'Day la tin Sacrasm'\n",
        "  else:\n",
        "    re = 'Day khong phai tin Sacrasm'\n",
        "  return re\n",
        "\n",
        "print ('Model Naive Bayes: ', check(Kqua1))\n",
        "print ('Model KNN: ', check(Kqua2))\n",
        "print ('Model SVM: ', check(Kqua3))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Moi nhap headline: I Am George Floyd': Air Force's Top Enlisted Leader Denounces Police Killing\n",
            "Model Naive Bayes:  Day la tin Sacrasm\n",
            "Model KNN:  Day la tin Sacrasm\n",
            "Model SVM:  Day khong phai tin Sacrasm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qHI-D_BgXBc",
        "colab_type": "text"
      },
      "source": [
        "# Trả lời câu hỏi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro6xDx2vgbMq",
        "colab_type": "text"
      },
      "source": [
        "1. Mô tả bài toán ở trên cùng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT-2VJIMgg4h",
        "colab_type": "text"
      },
      "source": [
        "2. Thu thâp headline ở 2 trang web trên, em sử dụng 1 tool extentions ở gooogle chrome có tên là Data miner để crawl dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvSupGdCgqMQ",
        "colab_type": "text"
      },
      "source": [
        "3. Chúng em sử dụng 2 phương pháp để rút trích đặc trưng là Bag of Words (túi từ - sử dụng khoảng 2000 từ thường xuất hiện nhất)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bkbDeukgykD",
        "colab_type": "text"
      },
      "source": [
        "4. Em sử test trên 3 thuật toán là KNN, Naive Bayes, svm và thấy model khi dùng svm là cho tỉ lệ dự đoán cao nhất khoảng 77% trên tập test đc chia ra từ Data. Em chưa tuning bất kì thuật toán nào cả."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-HyVXt7JUSF",
        "colab_type": "text"
      },
      "source": [
        "5. Model đã train sẽ được lưu lại thông qua thư viện joblib, chương trình đưa 1 headline mới vào để dự đoán được viết ở phía trên.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfqEYnb7J1EU",
        "colab_type": "text"
      },
      "source": [
        "6. Performance ở trường hợp 3 trường hợp của 3 model Naive Bayes, KNN, SVM đều khá tệ\n",
        "\n",
        "  1. Naive Bayes -> Dự đoán tất cả headline đầu vào đều là Sacrasm\n",
        "  2. KNN -> Dự đoán chỉ số F1 Score cũng như Accurancy khá thấp\n",
        "  3. SVM -> Dự đoán toàn bộ headline đầu vào đều là non-sacrasm\n",
        "\n",
        "  Nguyên do dự đoán khá tệ:\n",
        "  1. Có thể chưa tuning hyperparmeters\n",
        "  2. Do khâu rút trích đặc trưng bằng Bag of words khá tệ (đây là kĩ thuật thô sơ, không biểu diễn không rõ giá trị của các từ trong câu như các kĩ thuật tiên tiến hơn, chỉ biểu diễn được 1 câu tốt nhất khi tất cả từ trong câu đó đều có trong từ vựng (được tạo ra trước đó trong túi từ), và nếu là phương pháp BOW thì câu \"Tôi đi học\" sẽ tương đương với \"đi học tôi\" hoặc \"đi tôi học\".\n",
        "\n",
        "  Có thể em sẽ nghiên cứu thêm những kĩ thuật rút trích đặc trưng hiện đại hơn như word embedding, word2vec để cải thiện hiệu suất của model.\n",
        "\n",
        "\n"
      ]
    }
  ]
}